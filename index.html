<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Brown University CSCI2951-P - Human-Robot Interaction Seminar</title>
    <meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0;">

    <!-- Combo with CSSNormalize, CSSGrids-Responsive, CSSForm, CSSTable, CSSList (v3.9.1) -->
    <link rel="stylesheet" href="http://yui.yahooapis.com/combo?3.9.1/build/cssnormalize/cssnormalize-min.css&amp;3.9.1/build/cssgrids-responsive/cssgrids-responsive-min.css&amp;3.9.1/build/cssbutton/cssbutton-min.css&amp;gallery-2013.03.27-22-06/build/gallerycss-csslist/gallerycss-csslist-min.css&amp;gallery-2013.03.27-22-06/build/gallerycss-csstable/gallerycss-csstable-min.css&amp;gallery-2013.03.27-22-06/build/gallerycss-cssform/gallerycss-cssform-min.css">
    
    <!-- Some custom styles to make things pretty. -->
    <link rel="stylesheet" type="text/css" href="https://rawgithub.com/tilomitra/prettypages/gh-pages/ui.css">

    <!-- RainbowJS Syntax Highlighting - Github Theme. 
         For more themes, go to https://github.com/ccampbell/rainbow/tree/master/themes -->
    <link rel="stylesheet" type="text/css" href="https://rawgithub.com/ccampbell/rainbow/master/themes/github.css">

    <!-- Modify header colors here to customize the look and feel of the site-->
    <style>
        
        .header {
            background: rgb(53, 41, 116);
         }
            .header h1 {
                color: white;
            }
             .header h2 {
                 font-weight:300;
                 margin:0;
                 color: rgb(116, 130, 230);
             }
    </style>

</head>

<body class='yui3-skin-sam'>

    <div id="headerMenu" class="yui3-menu yui3-menu-open yui3-menu-horizontal yui3-menu-fixed">
        <span class="yui3-menu-heading">BrownCSCI2951-P</span>
        <ul>
            <li class="yui3-menu-active"><a href="#schedule">schedule</a></li>
            <li><a href="http://github.com/BrownCSCSCI2951-P/">github</a></li>
            <!--
            <li><a href="#assignment1">Project 1</a></li>
            <li><a href="#assignment2">Project 2</a></li>
            <li><a href="#assignment3">Project 3</a></li>
            <li><a href="#assignment4">Project 4</a></li>
            <li><a href="#assignment5">Final Project</a></li>
            -->
        </ul>
    </div>
    <div class="header yui3-u-1">

        <h1 class="yui3-u-1">Brown CSCI2951-P</h1>
        <h2 class="yui3-u">Human-Robot Interaction Seminar</h2>
        <br>
        <h2 class="yui3-u">Fall 2014</h2>
        <p>
        <h2 class="yui3-u">Building Human-usable 3D Maps for Robots</h2>

     </div>
    <div class="content">
<p>
<!--
<center><h2>Creating Human  interactive maps from Robot sensing"</h2></center>
-->
<center><img width=800 src="134_table.png"></center>

        <h2>Introduction</h2>

<p>

CSCI2951-P is a seminar course on Human-Robot Interaction (HRI). The theme of the HRI Seminar in Fall 2014 is "Building Human-usable 3D Map for Robots".  Consider how interactive 2D maps of the world have become commonplace, almost essential, in our daily lives.  Map services from companies such as Mapquest, Google, Apple, etc. are used in many different ways to help our decision making about where to go, where to shop, where to live, and a plethora of our activities.  Maps from these services contain not only physical descriptions of space (such as geospatial locations, metric geographic terrain, street views) but also important semantic information (navigation graphs, directory labels, ratings).  Such maps are also the basis for autonomous decision making for advising people as well as for robot control.  For example, route directions provided by a mapping service between locations is generated by a planner that searches for optimal paths in the map.  Similarly, a robot will use a planner on a map to autonomously move across the locations in a building.  However, this requires a map building phase followed by a labeling phase and then a planning phase. Building on advances in depth sensing technologies, we will focus on building maps using Red-Green-Blue-Depth (RGBD) sensors, such as the Microsoft Kinect, followed by interactively labeling these maps so that they can be used to plan and execute a task by robots such as the Willow Garage PR2. 
<p>

This course focuses on SLAM part of robotics and how human interaction on these maps would help in building better maps.  We will cover topics that address the perceptual challenges involved in robotics for estimating 3D maps. The course will go over basic concepts in robot sensing (from odometry, laser rangefinding, RGBD sensors and cameras) and robot mapping and state estimation (including Simultaneous Localization and Mapping, or SLAM).  We will additionally cover new exploratory ideas for semantic labeling of maps through recent publications in robot learning from demonstration, semantic mapping, geometry sketching, etc.  We will essentially discuss research papers covering the following areas:

<ul> 
<li> Smoothing RGBD data from Kinect, 
</li>
<li> Basic RGBD Mapping, 
</li>
<li> SLAM and mapping methods in robotics (SGD, iSAM, FastSLAM, EKF, ICP) 
</li>
<li> Human-in-the-loop map building and labeling </b>. 
</li>
</ul>


<!--We answer this question through a series of lectures, class discussions, and group projects. -->
<p>
This year, CSCI2951-P course work will involve each individual in the class:

<ul>
<li> presenting at least two papers during the entire semester (of course, the course staff will help you understand the technical details),
</li>
<li> completing 4 programming assignments building up to 3D RGBD mapping, 
</li>
<li> developing and implementing a final project to involving a human-usable interface to a build map
</li>
</ul>

<!--These projects will explore various approaches to robot decision making (spanning reaction to deliberation), perception (basic object recognition and state estimation), and control (proportional-derivative servos). -->

<p>

<h2>Course Staff</h2>
<h3>Instructor</h3> Prof. Chad Jenkins 
<br>Office Hours: TBA
<h3>Teaching Assistant</h3> Karthik Desingh
<br>Office Hours: Fridays 10am - 12pm at CIT 449
<h3>Admin</h3>Prof. Jenkins administrative support person is Suzanne Alden.

<h2>Meeting time/place</h2>

<p>
Monday 3:00-5:20 (M Hour) <br>
CIT Lubrano (Class session) and CIT 115 (Lab session)

<h2>Mailing list:</h2>
TBA

<h2>Optional Textbook</h2>
<a href="http://www.robots.ox.ac.uk/~vgg/hzbook/">Multi-view Geometry in Computer Vision</a>, Hartley and Zisserman, Cambridge University Press, 2004.

<h2>Prerequisites:</h2> 
<p>
Linear Algebra (CS 53 or equivalent) <p> 
and one of: <br>
Autonomous Robotics (CS 148), Computer Vision (CS 143), Computer Graphics (CS 123), Artificial Intelligence (CS 141)  <p>
or instructor permission
<br>


<h2 id="schedule">Schedule (tentative)</h2>

<!-- cjenkins: partial citations for papers formatted as: title, abbreviated author list, venue (with volume and number if journal), year. -->

<table cellpadding=5 border=1  width="100%">
<tr>    
        <td style="width:30px"><b><center>Week</center></b></td> 
        <td style="width:50px"><b><center>Date</center></b></td> 
        <td style="width:600px"><b><center>Class session</center></b></td>
        <td style="width:75px"><b><center>Presenters</center></b></td>
        <td style="width:200px"><b><center>Lab session</center></b></td>
        <td style="width:75px"><b><center>Slides</center></b></td>
        <td style="width:100px"><b><center>Projects</center></b></td>
</tr>

<tr>
    <td>1</td>
    <td>Sept 8</td>
    <td>
         <u> Initialization </u><br>
         Introduction, Paper assignments, etc.
    </td>
    <td>Chad</td> 
    <td>RGBD SLAM demos</td>
    <td></td> 
    <td>Mini Projects 1, 2, 3 - Out!</td> 
</tr>

<tr>
    <td>2</td>
    <td>Sept 15</td>
    <td>
        <i>In-class refresher: 3D transforms and odometry</i>

            <!-- u> Point-based Modeling </u --><br><br>

         <a href="http://rvsn.csail.mit.edu/content/eolson/graphoptim/eolson-graphoptim2006.pdf">Fast Iterative Alignment of Pose Graphs with Poor Initial Estimates</a>, Olson et al., International Conference on Robotics and Automation, 2006.
        <br> <br>
	    <a href="http://www.cs.tau.ac.il/~dcor/online_papers/papers/points_set_vis01.pdf">Point Set Surfaces</a>, Alexa et al., IEEE Visualization, 2001.

	    <!--a href="http://infoscience.epfl.ch/record/149334/files/pauly_2003_SMP.pdf">Shape Modeling with Point-Sampled Geometry</a>, Pauly et al., ACM SIGGRAPH, 2003. -->
	    
    </td>
    <td></td> 
    <td>Introduction to Point Cloud Library</td> 
    <td></td>
    <td>ROSBags data out</td>
</tr>

<tr>
    <td>3</td>
    <td>Sept 22</td>
    <td>

	    <a href="https://www.willowgarage.com/sites/default/files/icra11_0.pdf">3D is here: Point Cloud Library</a>, Rusu and Cousins, International Conference on Robotics and Automation, 2011.
        <br><br>
        <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.87.5313">Visual Odometry</a>, Nister et al., Computer Vision and Pattern Recognition, 2004.
    </td>
    <td></td> 
    <td>Hacking session on Mini Projects</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>4</td>
    <td>Sept 29</td>
    <td>
	    <a href="http://www2.seattle.intel-research.net/~xren/publication/3d-mapping-iser-10-final.pdf">RGBD Mapping: Using Depth Cameras for Dense 3D Modeling of Indoor Environments</a>, Henry et al., International Symposium on Experimental Robotics, 2010.
        <br><br>
        <a href="http://www2.informatik.uni-freiburg.de/~endres/files/publications/endres13tro.pdf">3D Mapping with an RGB-D Camera</a> Endres et al., IEEE Transactions on Robotics, 30(1), 2014.
    </td>
    <td></td> 
    <td>Hacking session on Mini Projects</td> 
    <td></td>
    <td>Project 1 due; Project 2 out - RGBD Mapping</td>
</tr>

<tr>
    <td>5</td>
    <td>Oct 6</td>
    <td>
	    <a href="http://www.i3s.unice.fr/~comport/publications/2013_IROS_Meilland.pdf">On unifying key-frame and voxel-based dense visual SLAM at large scales</a>, Meilland and Comport, IEEE Intelligent Robots and Systems, 2013.
        <br> <br>        
        <a href="http://vision.in.tum.de/_media/spezial/bib/schoeps14ismar.pdf">Semi-Dense Visual Odometry for AR on a Smartphone</a>, T. Schöps, J. Engel, D. Cremers, ISMAR, 2014.
    </td>
    <td></td> 
    <td>Hacking session on Mini Projects</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>6</td>
    <td>Oct 13</td>
    <td>
            Fall Weekend Holiday! 
    </td>
    <td></td>
    <td></td> 
    <td></td>
    <td>Mini Projects due; Project 4 - SLAM out</td>
</tr>

<tr>
    <td>7</td>
    <td>Oct 20</td>
    <td>

        <a href="http://www.cc.gatech.edu/~kaess/pub/Kaess08tro.pdf">iSAM: Incremental Smoothing and Mapping</a>, Kaess et al., IEEE Transactions on Robotics, 24(6) 2008.    
	    <br> <br>
	    <a href="http://www.roboticsproceedings.org/rss08/p40.pdf">Inference on networks of mixtures for robust robot mapping</a>, Olson and Agarwal, Robotics: Science and Systems, 2012.
    </td>
    <td></td> 
    <td>Hacking session on SLAM project</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>8</td>
    <td>Oct 27</td>
    <td>
        <a href="http://everobotics.org/pdf/SLAMTutorial.pdf">Simultaneous Localization and Mapping: Part 1</a>, Durrant-Whyte and Bailey, IEEE Robotics and Automation Magazine, June 2006.
        <br> <br>
        <a href="http://ai.stanford.edu/~koller/Papers/Montemerlo+al:AAAI02.pdf">FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem</a>, Montemerlo et al., AAAI, 2002.

    </td>
    <td></td> 
    <td>Hacking session on SLAM project</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>9</td>
    <td>Nov 3</td>
    <td>
        <a href="http://cg.cs.tsinghua.edu.cn/papers/SIGASIA-2013-3sweep.pdf">3-Sweep: Extracting Editable Objects from a Single Photo</a>, Chen et al., ACM SIGGRAPH Asia, 2013.
	    <br> <br>
	    <a href="http://www.robots.ox.ac.uk/~phst/Papers/2007/SIGGRAPH/Siggraph07FinalSmall.pdf">VideoTrace: Rapid interactive scene modelling from video</a>, van den Hengel et al., ACM SIGGRAPH, 2007.
        <br> <br>
        KML - Keyhole Markup Language - briefing.
    </td>
    <td></td> 
    <td>Hacking session on SLAM project</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>10</td>
    <td>Nov 10</td>
    <td>
        <a href="http://www.leilatakayama.org/downloads/Takayama.HitLGrasping_HRI2012_prepress.pdf">Strategies for Human-in-the-Loop Robotic Grasping</a>, Kaijen et., HRI, 2012.
        <br> <br>
        <a href="http://www.ccs.neu.edu/home/atp/publications/affordances_iser2014.pdf">Localizing Handle-like Grasp Affordances in 3DPoint Clouds</a>, Platt et al., ISER 2014
        <br> <br>
        NASA Valkyrie Affordance Templates
    </td>
    <td></td> 
    <td>SLAM project demos</td> 
    <td></td>
    <td>Project 4 - SLAM due! Final Project out!</td>
</tr>

<tr>
    <td>11</td>
    <td>Nov 17</td>
    <td>
	    <a href="http://smartech.gatech.edu/bitstream/handle/1853/42279/Towards%20Grounding%20Concepts%20for%20Transfer%20in%20Goal%20Learning%20from%20Demonstration.pdf">Towards grounding concepts for transfer in goal learning from demonstration</a>, Chao et al., International Conference on Development and Learning, 2011.
        </br>
	    <br> <br>
        <a href="https://smartech.gatech.edu/jspui/bitstream/1853/37382/1/hri2008.pdf">A Point-and-Click Interface for the Real World: Laser Designation of Objects for Mobile Manipulation</a>, Kemp et al., Human-Robot Interaction Conference, 2008.
        <br><br>
        Robot Web Tools 

    </td>
    <td></td> 
    <td>Hacking session on final project</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>12</td>
    <td>Nov 24</td>
    <td>
        Thanksgiving Break! 
    </td>
    <td></td> 
    <td>Hacking session on final project</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>13</td>
    <td>Dec 1</td>
    <td>Final project proposal presentations and main project checkin meeting</td>
    <td></td> 
    <td>Hacking session on final project</td> 
    <td></td>
    <td></td>
</tr>

<tr>
    <td>14</td>
    <td>Dec 8</td>
    <td>Final Project demos and Presentation</td>
    <td></td> 
    <td></td> 
    <td></td>
    <td>Final Project due!</td>
</tr>

</table>


<h2>Projects and Grading</h2>

<p>
Students will be assigned 2 papers to present (depends on the enrollment of students) and do 5 projects. 5 projects are categorized as 3 mini projects, SLAM project and final project. CSCI2951-P projects are graded as “checked” (completed) or “not checked” (incomplete). To receive an A grade in the course, you must present 2 papers in class, write summary to papers each week and have all 5 projects checked by the end of reading period. For a B grade, 1 paper must be presented and 2/3 mini projects along with SLAM project and final project must be checked. Less than 4 checks or presenting 0 papers or no participation in writing summaries will result in no credit for the course.  If enrollment limits the number of presentation slots, the instructor may ask for the second paper presentation by a student be done by recorded video or written report.  The timing and due dates for these projects will be announced on an ongoing basis, with a tentative schedule above.
</br>
<p>
The projects will be:
<ul>
<li>Moving Least Squares: estimate the surface underlying a set of 3D points by implementing the Moving Least Squares algorithm</li>
<li>RGBD Mapping: map a 3D geometry of space from RGBD depth video and odometry collected from a Kinect camera mounted on a robot</li>
<li>SGD-SLAM: perform simultaneous localization and mapping for a pose graph of robot motion collected from odometry and given loop closures</li>
<li>Implement any SLAM algorithm</li>
</ul>

<p>
The final project involves the design and implementation of a human-usable interface for labeling a map built from the course programming assignments.  This interface should enable a random human user to create a geomtry for an object in a built map.

<p>
All the project deadlines will have a demo by the students in the lab session. Final project will also require a presentation by students regarding the various methods they studied and employed.  
<p>
Git repositories will be used for project implementation, version control, and submission. Project implementations are submitted as branches in your assigned repository. These branches must be submitted prior to the due date for each assignment. Your implementation will be checked out and executed by the course staff. You will be notified by the course staff whether your implementation is sufficient for checking off the assignment. If your assignment is insufficient for receiving a check, your group is allowed one regrade (per assignment) with 2 weeks of notification. If deemed necessary, the course staff may require an interactive demonstration of your implementation and/or a web-based written report.

<h3>Final Grading</h3>

All grading will be finalized on <b>December 10, 2014</b>, after final project presentations.  

<!--Regrading of specific assignments will be done upon request during office hours.  No regrading will be done after grades are finalized.-->

<h3>Repositories</h3>

<p>
The course staff will provide a git repository (through github) for each student group to check in project source code and reports, unless you request using separate service or repository. Please refer to <a href="http://www-cs-students.stanford.edu/~blynn/gitmagic/">this tutorial</a> for an in-depth introduction to git and version control.  Although it has a coarse language choice, this is also a great and accessible <a href="http://rogerdudler.github.io/git-guide/">tutorial<a>.  We expect students to use these repositories for collaborative development as well as project submission. It is the responsibility of each student group to ensure their repository adheres to the Collaboration Policy and submission standards for each assignment. Submission standards and examples will be described for each assignment.

<h3>Late Policy</h3>
<p>
Do not be late submitting assignments. The course staff reserves the right to not grade late submissions.  

<h2>Collaboration Policy</h2>
<p>

 This policy covers all course material and assignments unless otherwise stated. Course material information and documentation may be discussed with anyone. Course material does not include assignment handouts. Assignments may be discussed with the other CSCI2951-P students. Discussions may make use of a whiteboard or paper. Discussions outside of your group cannot include writing or debugging code on a computer. You may take notes away from these discussions, provided these notes do not include any source code.

The code for your implementation may not be shown to anyone outside of your group, including granting access to repositories or careless lack of protection. You do not need to hide the screen from anyone, but you should not attempt to show anyone your code. When you are done using any robot device such that another group may use it, you must remove all code you have put onto the device. You may not share your code with others outside of your group. At any time, you may show others the implemented program running on a device or simulator, but you may not discuss specific debugging details about your code while doing so.

Should you fail to abide by this policy, you will receive no credit for this course. Brown also reserves the right to pursue any means necessary to ensure compliance. This includes, but is not limited to prosecution through Brown University’s Student Conduct Procedures, which can result in your suspension or expulsion from the University 


        <!-- TYPEKIT -->
        <script type="text/javascript" src="//use.typekit.net/ajf8ggy.js"></script>
        <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/rainbow.min.js"></script>
        <script src="https://rawgithub.com/ccampbell/rainbow/master/js/language/generic.js"></script>
    </div>
</body>
</html>
